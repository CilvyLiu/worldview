import streamlit as st
import akshare as ak
import pandas as pd
import numpy as np
import requests
import random
import time
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# =================== 1. åè®®ç©¿é€å¼•æ“Ž (Nova ä¸“å±žï¼šæŠ—å°é”åŒè½¨ç‰ˆ) ===================

class NovaRobustConnector:
    """å…·å¤‡æŒ‡çº¹ä¼ªè£…ä¸ŽæŒ‡æ•°é€€é¿é‡è¿žçš„é¡¶çº§è¿žæŽ¥å™¨"""
    def __init__(self):
        self.session = requests.Session()
        # å®šä¹‰é‡è¯•è§„åˆ™ï¼šé’ˆå¯¹ç‰©ç†æ–­å¼€ã€è¿žæŽ¥è¶…æ—¶è‡ªåŠ¨é‡è¯• 5 æ¬¡
        retries = Retry(
            total=5,
            backoff_factor=1,  # å¤±è´¥åŽç­‰å¾…æ—¶é—´ä¾æ¬¡å¢žåŠ  (1s, 2s, 4s...)
            status_forcelist=[500, 502, 503, 504],
            raise_on_status=False
        )
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

    def get_dynamic_headers(self):
        """ç”Ÿæˆéšæœºæµè§ˆå™¨æŒ‡çº¹"""
        chrome_ver = f"{random.randint(110, 122)}.0.{random.randint(1000, 6000)}.{random.randint(10, 200)}"
        return {
            "User-Agent": f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_ver} Safari/537.36",
            "Referer": "https://quote.eastmoney.com/center/boardlist.html",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Connection": "keep-alive"
        }

    def fetch(self, url, params):
        """æ ¸å¿ƒæ‹‰å–æ–¹æ³•ï¼šæ³¨å…¥éšæœºæŒ‡çº¹ä¸Žé˜²æŠ–å»¶è¿Ÿ"""
        try:
            params['cb'] = f"jQuery{random.randint(1000000, 9999999)}_{int(time.time()*1000)}"
            params['_'] = int(time.time()*1000)
            
            # å…³é”®ï¼šæ¨¡æ‹Ÿäººå·¥ç‚¹å‡»é—´çš„å¾®å°é—´éš”
            time.sleep(random.uniform(0.3, 0.7))
            
            resp = self.session.get(url, params=params, headers=self.get_dynamic_headers(), timeout=15)
            # æå– JSON æ•°æ® (å¤„ç† jQuery å›žè°ƒåŒ…è£¹)
            text = resp.text
            if not text or "(" not in text:
                return None
            json_str = text[text.find("(")+1 : text.rfind(")")]
            import json
            return json.loads(json_str)
        except Exception:
            return None

# å…¨å±€å…±ç”¨ä¸€ä¸ª Connector å®žä¾‹
if 'nova_conn' not in st.session_state:
    st.session_state.nova_conn = NovaRobustConnector()

@st.cache_data(ttl=300) # 5åˆ†é’Ÿå†…ä¸å†é‡å¤è¯·æ±‚ç›¸åŒæ¿å—ï¼Œé˜²æ­¢å° IP
def get_market_sectors_cached():
    """æ¿å—ä¾¦æµ‹ï¼šé‡‡ç”¨å¼ºåŒ–ç‰ˆç©¿é€åè®®"""
    url = "https://push2.eastmoney.com/api/qt/clist/get"
    params = {
        "pn": "1", "pz": "100", "po": "1", "np": "1",
        "ut": "b2884a393a59ad64002292a3e90d46a5",
        "fltt": "2", "invt": "2", "fid": "f62",
        "fs": "m:90+t:2+f:!50",
        "fields": "f12,f14,f3,f62,f184"
    }
    data = st.session_state.nova_conn.fetch(url, params)
    if data and 'data' in data and 'diff' in data:
        df = pd.DataFrame(data['data']['diff']).rename(columns={
            'f12': 'ID', 'f14': 'æ¿å—åç§°', 'f3': 'ä»Šæ—¥æ¶¨å¹…', 
            'f62': 'ä¸»åŠ›å‡€é¢', 'f184': 'ä¸»åŠ›å æ¯”'
        })
        df['æ¿å—è¯„åˆ†'] = pd.to_numeric(df['ä¸»åŠ›å‡€é¢'], errors='coerce') / 100000000
        return df.sort_values(by='æ¿å—è¯„åˆ†', ascending=False)
    return None

@st.cache_data(ttl=60) # 1åˆ†é’Ÿç¼“å­˜ï¼Œé¿å…æ“ä½œä¸‹æ‹‰æ¡†æ—¶é‡å¤è¯·æ±‚ä¸ªè‚¡æ•°æ®
def get_stock_penetration_cached(sector_id):
    """ä¸ªè‚¡ç©¿é€ï¼šæ”¯æŒé•¿æ•ˆ Session åè®®"""
    url = "https://push2.eastmoney.com/api/qt/clist/get"
    params = {
        "pn": "1", "pz": "100", "po": "1", "np": "1",
        "ut": "8dec03ba335b81bf4ebdf7b29ec27d15",
        "fltt": "2", "invt": "2", "fid": "f164",
        "fs": f"b:{sector_id}",
        "fields": "f12,f14,f2,f3,f62,f164,f174"
    }
    data = st.session_state.nova_conn.fetch(url, params)
    if data and 'data' in data and 'diff' in data:
        df = pd.DataFrame(data['data']['diff']).rename(columns={
            'f12': 'ä»£ç ', 'f14': 'åç§°', 'f2': 'ä»·æ ¼', 'f3': 'ä»Šæ—¥æ¶¨å¹…',
            'f62': 'ä»Šæ—¥ä¸»åŠ›', 'f164': '5æ—¥ä¸»åŠ›', 'f174': '10æ—¥ä¸»åŠ›'
        })
        for c in ['ä»Šæ—¥ä¸»åŠ›', '5æ—¥ä¸»åŠ›', '10æ—¥ä¸»åŠ›']:
            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0) / 10000
        return df
    return None

# =================== 2. æ‰«è´§ç—•è¿¹å®¡è®¡ (Nova æ ¸å¿ƒç®—æ³•) ===================

class StrategicSniffer:
    def get_real_trade_dates(self, count=3):
        try:
            df = ak.stock_zh_index_daily(symbol="sh000001")
            return df['date'].tail(count).dt.strftime("%Y%m%d").tolist()[::-1]
        except: return [datetime.now().strftime("%Y%m%d")]

    def analyze_silent_trace(self, df_tick):
        if df_tick is None or df_tick.empty: return 0
        df_tick['price'] = pd.to_numeric(df_tick['price'], errors='coerce')
        df_tick['æˆäº¤é¢'] = pd.to_numeric(df_tick['æˆäº¤é¢'], errors='coerce')
        n_df = df_tick[df_tick['type'] == 'ä¸­æ€§']
        n_ratio = len(n_df) / len(df_tick) if len(df_tick) > 0 else 0
        p_std = df_tick['price'].std()
        
        score = 0
        if n_ratio > 0.40: score += 2 
        if p_std is not None and p_std < 0.005: score += 2  
        return score

# =================== 3. åŠ¨æ€ä¾¦æµ‹ UI ===================

st.set_page_config(page_title="Sniffer Pro V12.0", layout="wide")
sniffer = StrategicSniffer()
dates = sniffer.get_real_trade_dates(3)

st.title("ðŸ›ï¸ Sniffer Pro V12.0 - æŠ•è¡Œçº§ç¨³å¥ç³»ç»Ÿ")
st.caption(f"Nova ä¸“å±žæ¨¡å¼ | å·²æ¿€æ´»éšæœºæŒ‡çº¹å¯¹æŠ—åè®®")

# --- Step 1 ---
st.header("Step 1: å…¨å¸‚åœºæ¿å—èµ„é‡‘ä¾¦æµ‹")
df_all = get_market_sectors_cached()

if df_all is not None:
    st.dataframe(df_all, use_container_width=True)
    csv_s1 = df_all.to_csv(index=False).encode('utf_8_sig')
    st.download_button("ðŸ“¥ å¯¼å‡ºæ¿å—æŠ¥å‘Š", data=csv_s1, file_name="Sectors.csv")
    
    st.divider()
    s_map = df_all.set_index('æ¿å—åç§°')['ID'].to_dict()
    target_sec = st.selectbox("ðŸŽ¯ é€‰å®šå¾…å®¡è®¡æ¿å—:", ["è¯·é€‰æ‹©æŽ¢æµ‹ç›®æ ‡"] + list(s_map.keys()))

    if target_sec != "è¯·é€‰æ‹©æŽ¢æµ‹ç›®æ ‡":
        sid = s_map[target_sec]
        # --- Step 2 ---
        st.header(f"Step 2: {target_sec} - ä¸ªè‚¡ä¾¦æµ‹")
        df_s = get_stock_penetration_cached(sid)
        if df_s is not None:
            df_s['ä¾¦æµ‹çŠ¶æ€'] = np.where((df_s['5æ—¥ä¸»åŠ›'] > 500) & (df_s['ä»Šæ—¥æ¶¨å¹…'] < 1.5), "ðŸ’Ž ç–‘ä¼¼é™é»˜æ‰«è´§", "æ­£å¸¸æ³¢åŠ¨")
            st.dataframe(df_s, use_container_width=True)
            
            # --- Step 3 ---
            st.divider()
            st.header("Step 3: ä¸‰æ—¥æ·±åº¦å¤ç›˜")
            targets = st.multiselect("å‹¾é€‰æ ‡çš„:", df_s['åç§°'].tolist(), 
                                     default=df_s[df_s['ä¾¦æµ‹çŠ¶æ€']=="ðŸ’Ž ç–‘ä¼¼é™é»˜æ‰«è´§"]['åç§°'].tolist()[:2])
            
            if targets:
                if st.button("ðŸ” å¼€å§‹æ‰§è¡Œ Tick å®¡è®¡ (Nova ç®—æ³•)"):
                    reports = []
                    p_bar = st.progress(0)
                    selected = df_s[df_s['åç§°'].isin(targets)]
                    for idx, (s_idx, row) in enumerate(selected.iterrows()):
                        c = str(row['ä»£ç ']).zfill(6)
                        f = f"{'sh' if c.startswith('6') else 'sz'}{c}"
                        r = {"åç§°": row['åç§°'], "å®¡è®¡å¾—åˆ†": 0}
                        ts = 0
                        for d in dates:
                            try:
                                d_t = ak.stock_zh_a_tick_163(symbol=f, date=d)
                                s = sniffer.analyze_silent_trace(d_t)
                            except: s = 0
                            ts += s
                        r["å®¡è®¡å¾—åˆ†"] = ts
                        reports.append(r)
                        p_bar.progress((idx + 1) / len(selected))
                    
                    st.table(pd.DataFrame(reports))
                    st.download_button("ðŸ“¥ å¯¼å‡ºæŠ¥å‘Š", pd.DataFrame(reports).to_csv(index=False).encode('utf_8_sig'), "Audit.csv")
else:
    st.info("ðŸ”„ æ­£åœ¨ç»•è¿‡é˜²ç«å¢™ï¼Œè¯·ç‚¹å‡»å³ä¾§ä¾§è¾¹æ  'Clear Cache' æˆ–ç¨åŽå†è¯•ã€‚")
